{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8654277",
   "metadata": {},
   "source": [
    "# Reconocimiento de patrones y aprendizaje automático\n",
    "\n",
    "## Tarea 3: Redes neuronales y árboles de decisión\n",
    "\n",
    "#### Profesor: Andrés Aldana Gonzáles<br> Ayudante: Felipe Navarrete Córdova<br> Alumno: Ricardo Eduardo Rivas Roa\n",
    "Fecha de entrega: Lunes 24 de enero de 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f292c530",
   "metadata": {},
   "source": [
    "## 1. Investigación\n",
    "Realiza un breve resumen donde contestes las siguientes preguntas:\n",
    "<br>$a)$¿Qué son las redes neuronales recurrentes (RNN’s)?\n",
    "\n",
    "$R.$ Una red neuronal recurrente (RNN) es un tipo de red neuronal artificial que utiliza datos secuenciales o datos de series temporales. Estos algoritmos de aprendizaje profundo se usan comúnmente para problemas ordinales o temporales, como traducción de idiomas, procesamiento de lenguaje natural (nlp), reconocimiento de voz y subtítulos de videos. Al igual que las redes neuronales convolucionales (CNN), las redes neuronales recurrentes utilizan datos de entrenamiento para aprender. Se distinguen por su \"memoria\", ya que toman información de entradas anteriores para influir en la entrada y salida actual.\n",
    "\n",
    "\n",
    "<br>$b)$Describe los diferentes tipos de RNN’s\n",
    "\n",
    "$R.$ Hay bastantes tipos de RRN's, particularmente aquí sólo vamos a explicar 4 tipos. \n",
    "* Primero, el tipo one-to-one: Un modelo one-to-one produce un valor de salida para cada valor de entrada.\n",
    "  ![one-to-one.png](one-to-one.png)\n",
    "\n",
    "El estado interno para el primer paso de tiempo es cero; a partir de ese momento, el estado interno se acumula sobre los pasos de tiempo anteriores así progresivamente. En el caso de una predicción de secuencia, este modelo produciría un pronóstico de un paso de tiempo para cada paso de tiempo observado recibido como entrada.\n",
    "\n",
    "* Un modelo one-to-many a muchos produce múltiples valores de salida para un valor de entrada.\n",
    "  ![one-to-many.png](one-to-many.png)\n",
    "  El estado interno se acumula a medida que se produce cada valor en la secuencia de salida.\n",
    "\n",
    "Este modelo se puede utilizar para subtítulos de imágenes en los que se proporciona una imagen como entrada y se genera una secuencia de palabras como salida.\n",
    "\n",
    "* Un modelo de many-to-one produce múltiples valores de salida para un valor de entrada.\n",
    "![many-to-one.png](many-to-one.png)\n",
    "El estado interno se acumula con cada valor de entrada antes de que se produzca un valor de salida final.\n",
    "\n",
    "En el caso de series de tiempo, este modelo usaría una secuencia de observaciones recientes para pronosticar el próximo paso de tiempo. Esta arquitectura representaría el modelo clásico de series temporales autorregresivas.\n",
    "\n",
    "* Un modelo de many-to-many produce múltiples salidas después de recibir múltiples valores de entrada.\n",
    "\n",
    "![many-to-many.png](many-to-many.png)\n",
    "\n",
    "Al igual que en el caso de many-to-one, el estado se acumula hasta que se crea la primera salida, pero en este caso se generan varios pasos de tiempo.\n",
    "\n",
    "Es importante destacar que el número de pasos de tiempo de entrada no tiene que coincidir con el número de pasos de tiempo de salida. Piense en los pasos de tiempo de entrada y salida que operan a diferentes velocidades.\n",
    "\n",
    "En el caso del pronóstico de series de tiempo, este modelo usaría una secuencia de observaciones recientes para hacer un pronóstico de varios pasos.\n",
    "\n",
    "<br>$c)$¿Qué tipo de problemas se pueden resolver a través de RNN’s?\n",
    "\n",
    "$R.$ Como se menciono en la primer pregunta esta red neuronal se usa en traducción de idiomas, procesamiento de lenguaje natural (nlp), reconocimiento de voz y genración de subtítulos; estas se incorporan a aplicaciones populares como Siri, búsqueda por voz y Google Translate.\n",
    "\n",
    "<br>$d)$¿Qué son las redes de tipo Long Short-Term Memory (LSTM)?\n",
    "\n",
    "$R.$ Es una variable de RNN que pretende resolver problema del gradiente de fuga de información. Esta variante agrega una manera para transportar información a través de muchos pasos de tiempo. La idea de este algoritmo es como tener una cinta transportadora corriendo paralela a la secuencia que se está procesando. La información de la secuencia puede saltar a la cinta transportadora en cualquier punto, ser transportado a un paso de tiempo posterior y saltar, intacto, cuando lo necesites. Esto es esencialmente lo que hace LSTM: guarda información para más adelante, evitando así que las señales más antiguas desaparezcan gradualmente durante el procesamiento.\n",
    "\n",
    "<br>$e)$Describe la arquitectura principal de una red LSTM\n",
    "\n",
    "$R.$ Para entender esto en detalle, comencemos desde la celda SimpleRNN. Debido a que tendrá muchas matrices de peso, indexe las matrices W y U en la celda con la letra o (Wo y Uo) para la salida.\n",
    "![lstm1.png](lstm1.png)\n",
    "Agreguemos a esta imagen un flujo de datos adicional que transporta información a través de pasos de tiempo. Llame a sus valores en diferentes intervalos de tiempo Ct, donde C significa acarreo. Esta información tendrá el siguiente impacto en la celda: se combinará con la entrada conexión y la conexión recurrente (a través de una transformación densa: un producto escalar\n",
    "con una matriz de ponderación seguida de una adición de sesgo y la aplicación de una función de activación), y afectará el estado que se envía al siguiente paso de tiempo (a través de una activación una función y una operación de multiplicación). Conceptualmente, el flujo de datos de acarreo es una forma de modular la siguiente salida y el siguiente estado.\n",
    "![lstm2.png](lstm2.png)\n",
    "Ahora la sutileza: la forma en que se calcula el siguiente valor del flujo de datos de acarreo. implica\n",
    "tres transformaciones distintas. Los tres tienen la forma de una celda SimpleRNN: $y = activation(dot(state_t, U) + dot(input_t, W) + b$ \n",
    "<br>Pero las tres transformaciones tienen sus propias matrices de peso, que indexará con las letras i, f y k. Esto es lo que tiene hasta ahora<br>\n",
    "$output_t = activation(dot(state_t, Uo) + dot(input_t, Wo) + dot(C_t, Vo) + bo)$<br>\n",
    "$i_t = activation(dot(state_t, Ui) + dot(input_t, Wi) + bi)$<br>\n",
    "$f_t = activation(dot(state_t, Uf) + dot(input_t, Wf) + bf)$<br>\n",
    "$k_t = activation(dot(state_t, Uk) + dot(input_t, Wk) + bk)$<br>\n",
    "Obtiene el nuevo estado de acarreo (el siguiente c_t) combinando i_t, f_t y k_t<br>\n",
    "$c_t+1 = i_t * k_t + c_t * f_t$<br>\n",
    "Agregue esto como se muestra en la figura. Y eso es todo.\n",
    "![lstm3.png](lstm3.png)\n",
    "\n",
    "\n",
    "<br>$f)$¿Cuál es la ventaja de usar LSTM en la predicción de series de tiempo sobre otros tipos de redes neuronales?\n",
    "\n",
    "$R.$ Como se mencionó anteriormente, no se tienen pérdidas de información debido al problema inherente de gradiente que tienen las RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069b127c",
   "metadata": {},
   "source": [
    "## 2. Implementación de redes neuronales\n",
    "El objetivo de este ejercicio es construir una red neuronal para clasificar el tipo de actividad que realiza una persona, usando como entrada los datos de un acelerómetro, que se encuentran en el archivo dataset2.zip. \n",
    "\n",
    "Los datos fueron recolectados de un acelerómetro puesto en el pecho de 15 participantes que realizan siete actividades. Los datos están separados por participante, por lo que hay 15 diferentes archivos, uno por cada participante con sus diferentes actividades.\n",
    "\n",
    "Estos datos fueron grabados con una frecuencia de 52 hz en tres direcciones x,y,z, por lo que cada segundo de registro del acelerómetro contiene 52 datos en tres dimensiones de la actividad que la persona está realizando.\n",
    "Cada columna es un atributo de la medición que representa:\n",
    "* Número serial o identificador\n",
    "* Aceleración x\n",
    "* Aceleración y\n",
    "* Aceleración z\n",
    "* Actividad\n",
    "La actividad está codificada por un número del 1-7:\n",
    "\n",
    "1. Trabajo en computadora\n",
    "2. Pararse, caminar y subir/bajar escaleras\n",
    "3. Mantenerse en pie\n",
    "4. Caminar\n",
    "5. Subir/bajar escaleras\n",
    "6. Caminar y hablar con alguien\n",
    "7. Hablar estando de pie\n",
    "\n",
    "### 2.1. Ejercicios\n",
    "1. Crea una red neuronal capaz de realizar la clasificación de la actividad. Recuerda dividir los datos en subconjuntos de entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa131d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9bfb37e",
   "metadata": {},
   "source": [
    "2. Determina el n ́umero  ́optimo de capas y neuronas por capa para este problema. Reporta tus\n",
    "resultados\n",
    "3. Prueba con diferentes funciones de activaci ́on: paso, sigmoide, tangente hiperb ́olica y relu.\n",
    "Reporta tus resultados\n",
    "4. Elabora un reporte en el que se indique:\n",
    "El preprocesamiento efectuado sobre los datos.\n",
    "El n ́umero de elementos utilizados como conjunto de entrenamiento y prueba.\n",
    "Matriz de confusi ́on e interpretaci ́on.\n",
    "Reporta el valor de las m ́etricas precisi ́on, exhaustividad (recall), exactitud (accuracy)\n",
    "y valor F1 (F1-Score) de este clasificador.\n",
    "¿C ́omo utilizar ́ıas funciones de activaci ́on continuas (como la sigmoide) para calibrar el\n",
    "rendimiento de la red neuronal?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a165b04",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "* Education, I., 2022. What are Recurrent Neural Networks?. [online] ibm.com. Available at: <https://www.ibm.com/cloud/learn/recurrent-neural-networks> [Accessed 21 January 2022].\n",
    "* Chollet, F., 2018. Deep learning with Python. Shelter Island, NY: Manning.\n",
    "* Amidi, A., 2019. CS 230 - Recurrent Neural Networks Cheatsheet. [online] Stanford.edu. Available at: <https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks> [Accessed 21 January 2022].\n",
    "* \n",
    "* Grus, J., 2015. Data Science from Scratch. 1st ed. 1005 Gravenstein Highway North, Sebastopol, CA 95472: O'Reilly Media, Inc. https://pdfroom.com/books/data-science-from-scratch/315v8qzPgYy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d18e21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
